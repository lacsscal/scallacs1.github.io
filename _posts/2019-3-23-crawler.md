# 前言 #
  在18年，其实写过一次爬虫，当时是刚刚大概掌握了python基础时的一次实践，其实大部分是参照网上的例子造轮子。同时，在当时的并没有接触过一些前端的知识，所以有相当大一部分的理论部分是似懂非懂的，现在，在几个小型的Python项目实践之后，决定自己尝试对**crawler**的一些理念深入了解，同时对之前的**爬虫**代码进行重构。

相关知识内容比较多，应该会写成几篇，本篇为基础理论知识，不涉及技术实现，相关内容大多来源于网络加入部分自己的理解

----
# 正文 #

在我们访问网络资源时，通常通过浏览器访问目标站点，目标站点会把HTML，JS，CSS的代码返回给浏览器，而浏览器会把这些代码解析渲染，让我们看到日常所见的网页。而爬虫模拟浏览器请求站点的行为，把站点返回的信息爬取到本地，然后提取出自己需要的数据存放起来。
即通过程序，自动抓取一些数据。

那么，爬虫的关键点即：**请求，抓取，自动化**

基本可将爬虫的流程拆分为四步：
	>发起请求
	>获取响应内容
	>解析内容
	>保存数据


